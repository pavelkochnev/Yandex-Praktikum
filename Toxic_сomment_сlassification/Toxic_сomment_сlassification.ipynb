{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация токсичных комментариев\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные со значением метрики качества *F1* не меньше 0.75. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все стоки заполнены, в данных нет пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['text'].astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на балансировку классов в выбоке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка несбалансироварована по классам. Количество \"токсичных\" комментариев примерно в 9 раз меньше чем количество простых комментариев. Необходимо это учитывать при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = make_pipeline(TfidfVectorizer(stop_words=stop_words), \n",
    "                       LogisticRegression(penalty='l2', solver='liblinear', C=11, \n",
    "                                          class_weight='balanced', random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77369495, 0.7682558 , 0.77161668, 0.77093668, 0.77205882])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_score = cross_val_score(lr_clf, corpus, data['toxic'], cv=5, scoring='f1')\n",
    "lr_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1 Score 0.7713'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'F1 Score {:.4f}'.format(lr_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = make_pipeline(TfidfVectorizer(stop_words=stop_words), \n",
    "                       ComplementNB(alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66780413, 0.65809943, 0.66564989, 0.65725944, 0.66380789])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_score = cross_val_score(nb_clf, corpus, data['toxic'], cv=5, scoring='f1')\n",
    "nb_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1 Score 0.6625'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'F1 Score {:.4f}'.format(nb_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_clf = make_pipeline(TfidfVectorizer(stop_words=stop_words), \n",
    "                       PassiveAggressiveClassifier(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7336178 , 0.72481828, 0.73579109, 0.73796142, 0.73746762])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_cv_score = cross_val_score(pa_clf, corpus, data['toxic'], cv=5, scoring='f1')\n",
    "pa_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1 Score 0.7339'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'F1 Score {:.4f}'.format(pa_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pool = Pool(data=data[['text']], label=data[['toxic']], text_features=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6707687\ttest: 0.6707687\tbest: 0.6707687 (0)\ttotal: 1.82s\tremaining: 16.4s\n",
      "9:\tlearn: 0.6707687\ttest: 0.6707687\tbest: 0.6707687 (0)\ttotal: 15.1s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "params = {\"iterations\": 10,\n",
    "          #\"depth\": 2,\n",
    "          \"loss_function\": \"Logloss\",\n",
    "          'eval_metric': 'F1',\n",
    "          'custom_metric': 'F1',\n",
    "          \"scale_pos_weight\": 9}\n",
    "\n",
    "cb_scores = cv(cv_pool, params, fold_count=5, verbose=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-F1-mean</th>\n",
       "      <th>test-F1-std</th>\n",
       "      <th>train-F1-mean</th>\n",
       "      <th>train-F1-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "      <th>test-F1:use_weights=true-mean</th>\n",
       "      <th>test-F1:use_weights=true-std</th>\n",
       "      <th>train-F1:use_weights=true-mean</th>\n",
       "      <th>train-F1:use_weights=true-std</th>\n",
       "      <th>test-F1:use_weights=false-mean</th>\n",
       "      <th>test-F1:use_weights=false-std</th>\n",
       "      <th>train-F1:use_weights=false-mean</th>\n",
       "      <th>train-F1:use_weights=false-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693145</td>\n",
       "      <td>1.641390e-09</td>\n",
       "      <td>0.693145</td>\n",
       "      <td>1.066827e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>3.264410e-09</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>2.070704e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693140</td>\n",
       "      <td>4.990489e-09</td>\n",
       "      <td>0.693140</td>\n",
       "      <td>2.892873e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693138</td>\n",
       "      <td>6.566405e-09</td>\n",
       "      <td>0.693138</td>\n",
       "      <td>3.788969e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693136</td>\n",
       "      <td>8.120855e-09</td>\n",
       "      <td>0.693136</td>\n",
       "      <td>4.631754e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693134</td>\n",
       "      <td>9.653409e-09</td>\n",
       "      <td>0.693134</td>\n",
       "      <td>5.424947e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693132</td>\n",
       "      <td>1.116296e-08</td>\n",
       "      <td>0.693132</td>\n",
       "      <td>6.171391e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693131</td>\n",
       "      <td>1.264907e-08</td>\n",
       "      <td>0.693131</td>\n",
       "      <td>6.873640e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693129</td>\n",
       "      <td>1.411082e-08</td>\n",
       "      <td>0.693129</td>\n",
       "      <td>7.534215e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>1.554818e-08</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>8.155974e-09</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.670769</td>\n",
       "      <td>8.612200e-07</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>5.869804e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iterations  test-F1-mean  test-F1-std  train-F1-mean  train-F1-std  \\\n",
       "0           0      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "1           1      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "2           2      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "3           3      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "4           4      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "5           5      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "6           6      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "7           7      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "8           8      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "9           9      0.670769     0.000003       0.670769  8.612200e-07   \n",
       "\n",
       "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \\\n",
       "0           0.693145      1.641390e-09            0.693145       1.066827e-09   \n",
       "1           0.693142      3.264410e-09            0.693142       2.070704e-09   \n",
       "2           0.693140      4.990489e-09            0.693140       2.892873e-09   \n",
       "3           0.693138      6.566405e-09            0.693138       3.788969e-09   \n",
       "4           0.693136      8.120855e-09            0.693136       4.631754e-09   \n",
       "5           0.693134      9.653409e-09            0.693134       5.424947e-09   \n",
       "6           0.693132      1.116296e-08            0.693132       6.171391e-09   \n",
       "7           0.693131      1.264907e-08            0.693131       6.873640e-09   \n",
       "8           0.693129      1.411082e-08            0.693129       7.534215e-09   \n",
       "9           0.693128      1.554818e-08            0.693128       8.155974e-09   \n",
       "\n",
       "   test-F1:use_weights=true-mean  test-F1:use_weights=true-std  \\\n",
       "0                       0.670769                      0.000003   \n",
       "1                       0.670769                      0.000003   \n",
       "2                       0.670769                      0.000003   \n",
       "3                       0.670769                      0.000003   \n",
       "4                       0.670769                      0.000003   \n",
       "5                       0.670769                      0.000003   \n",
       "6                       0.670769                      0.000003   \n",
       "7                       0.670769                      0.000003   \n",
       "8                       0.670769                      0.000003   \n",
       "9                       0.670769                      0.000003   \n",
       "\n",
       "   train-F1:use_weights=true-mean  train-F1:use_weights=true-std  \\\n",
       "0                        0.670769                   8.612200e-07   \n",
       "1                        0.670769                   8.612200e-07   \n",
       "2                        0.670769                   8.612200e-07   \n",
       "3                        0.670769                   8.612200e-07   \n",
       "4                        0.670769                   8.612200e-07   \n",
       "5                        0.670769                   8.612200e-07   \n",
       "6                        0.670769                   8.612200e-07   \n",
       "7                        0.670769                   8.612200e-07   \n",
       "8                        0.670769                   8.612200e-07   \n",
       "9                        0.670769                   8.612200e-07   \n",
       "\n",
       "   test-F1:use_weights=false-mean  test-F1:use_weights=false-std  \\\n",
       "0                        0.184589                       0.000002   \n",
       "1                        0.184589                       0.000002   \n",
       "2                        0.184589                       0.000002   \n",
       "3                        0.184589                       0.000002   \n",
       "4                        0.184589                       0.000002   \n",
       "5                        0.184589                       0.000002   \n",
       "6                        0.184589                       0.000002   \n",
       "7                        0.184589                       0.000002   \n",
       "8                        0.184589                       0.000002   \n",
       "9                        0.184589                       0.000002   \n",
       "\n",
       "   train-F1:use_weights=false-mean  train-F1:use_weights=false-std  \n",
       "0                         0.184589                    5.869804e-07  \n",
       "1                         0.184589                    5.869804e-07  \n",
       "2                         0.184589                    5.869804e-07  \n",
       "3                         0.184589                    5.869804e-07  \n",
       "4                         0.184589                    5.869804e-07  \n",
       "5                         0.184589                    5.869804e-07  \n",
       "6                         0.184589                    5.869804e-07  \n",
       "7                         0.184589                    5.869804e-07  \n",
       "8                         0.184589                    5.869804e-07  \n",
       "9                         0.184589                    5.869804e-07  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ниже представлен код который переберает веса моделей и ищет наилучший голосующий классификатор по заданному критерию\n",
    "# # так как перебор весов занимает порядка 45 мин код закомментирован.  \n",
    "# # модель с уже найдеными весами представлена в следующей ячейке\n",
    "\n",
    "# best_weights = []\n",
    "# best_mean_score = 0\n",
    "\n",
    "# for w0 in tqdm(np.arange(0, 1.1, 0.1)):\n",
    "#     w1 = 1 - w0\n",
    "#     voiting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('nb', nb_clf)],\n",
    "#                                   voting='soft', weights=[w0, w1])\n",
    "#     voiting_clf_score = cross_val_score(voiting_clf, corpus, data['toxic'], cv=5, scoring='f1')\n",
    "#     if voiting_clf_score.mean() > best_mean_score:\n",
    "#         best_mean_score = voiting_clf_score.mean()\n",
    "#         best_weights = [w0, w1]\n",
    "# best_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79107945, 0.78765432, 0.78515747, 0.78608964, 0.78873239])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voiting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('nb', nb_clf)],\n",
    "                              voting='soft', weights=[0.6, 0.4])\n",
    "\n",
    "voiting_clf_score = cross_val_score(voiting_clf, corpus, data['toxic'], cv=5, scoring='f1')\n",
    "voiting_clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1 Score 0.7877'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'F1 Score {:.4f}'.format(voiting_clf_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сводная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14ca\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >F1 Score Mean (5 Folds)</th>        <th class=\"col_heading level0 col1\" >F1 Score Std (5 Folds)</th>    </tr>    <tr>        <th class=\"index_name level0\" >Model</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14calevel0_row0\" class=\"row_heading level0 row0\" >Voting Classifier</th>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow0_col0\" class=\"data row0 col0\" >78.7743%</td>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow0_col1\" class=\"data row0 col1\" >0.2075%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14calevel0_row1\" class=\"row_heading level0 row1\" >Logistic Regression</th>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow1_col0\" class=\"data row1 col0\" >77.1313%</td>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow1_col1\" class=\"data row1 col1\" >0.1778%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14calevel0_row2\" class=\"row_heading level0 row2\" >Passive Aggressive Classifier</th>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow2_col0\" class=\"data row2 col0\" >73.3931%</td>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow2_col1\" class=\"data row2 col1\" >0.4803%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14calevel0_row3\" class=\"row_heading level0 row3\" >CatBoost (Text Features)</th>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow3_col0\" class=\"data row3 col0\" >67.0769%</td>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow3_col1\" class=\"data row3 col1\" >0.0003%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14calevel0_row4\" class=\"row_heading level0 row4\" >Complement Naive Bayes</th>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow4_col0\" class=\"data row4 col0\" >66.2524%</td>\n",
       "                        <td id=\"T_7900d045_8011_11eb_8296_a0b3cc4a14carow4_col1\" class=\"data row4 col1\" >0.4162%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b047007cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model': ['Logistic Regression', 'Complement Naive Bayes', 'Passive Aggressive Classifier', \n",
    "                                 'CatBoost (Text Features)', 'Voting Classifier'],\n",
    "                       'F1 Score Mean (5 Folds)': [lr_cv_score.mean(), nb_cv_score.mean(), pa_cv_score.mean(), \n",
    "                                            cb_scores.iloc[-1, 1], voiting_clf_score.mean()],\n",
    "                       'F1 Score Std (5 Folds)': [lr_cv_score.std(), nb_cv_score.std(), pa_cv_score.std(), \n",
    "                                            cb_scores.iloc[-1, 2], voiting_clf_score.std()]\n",
    "                     })\n",
    "\n",
    "\n",
    "(result.set_index('Model')\n",
    "       .sort_values('F1 Score Mean (5 Folds)', ascending=False)\n",
    "       .style.format({'F1 Score Mean (5 Folds)': \"{:.4%}\", 'F1 Score Std (5 Folds)': '{:.4%}'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По значению метрики F1 наилучшей является модель Voting Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе исследования были рассмотренны следующие модели:\n",
    "* Logistic Regression;\n",
    "* Complement Naive Bayes;\n",
    "* Passive Aggressive Classifier;\n",
    "* CatBoost;\n",
    "* Voting Classifier (Logistic Regression + Complement Naive Bayes).\n",
    "\n",
    "Из рассмотренных моделей заданным требованиям (метрика качества *F1* не меньше 0.75) соответствуют только модели Logistic Regression и Voting Classifier. Модель логистической регрессии дает метрику F1 - 0.7713. Объединение модели логистической регрессии и байесовской модели дает улучшение метрики до 0,7877."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
