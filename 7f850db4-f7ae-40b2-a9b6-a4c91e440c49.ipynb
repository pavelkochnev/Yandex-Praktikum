{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Отлично, что правильно использованы train/valid/test наборы.\n",
    "* Выводы и рассуждения получились содержательными, их было интересно читать.\n",
    "* Я оставил несколько советов, надеюсь, что они будут учтены в будущих проектах.\n",
    "* Тебе удалось добиться очень хорошего качества, поздравляю!\n",
    "* Данный проект зачтен. Удачи в дальнейшем обучении!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:\n",
    "* сalls — количество звонков,\n",
    "* minutes — суммарная длительность звонков в минутах,\n",
    "* messages — количество sms-сообщений,\n",
    "* mb_used — израсходованный интернет-трафик в Мб,\n",
    "* is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Загрузка и первичный анализ данных проведены успешно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных нет пропущенных строк. Значения в столбцах выглядят корректно предобработка данных не тебуется. Прежде чем перейти к разбиению данных на выбоки проведем замену тиов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calls': 'float64',\n",
       " 'minutes': 'float64',\n",
       " 'messages': 'float64',\n",
       " 'mb_used': 'float64',\n",
       " 'is_ultra': 'int64'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.apply(lambda x: x.name).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null int32\n",
      "minutes     3214 non-null float32\n",
      "messages    3214 non-null int16\n",
      "mb_used     3214 non-null float32\n",
      "is_ultra    3214 non-null int8\n",
      "dtypes: float32(2), int16(1), int32(1), int8(1)\n",
      "memory usage: 47.2 KB\n"
     ]
    }
   ],
   "source": [
    "# заменим типы в таблице по словарю df_type_dict\n",
    "df_type_dict = {\n",
    " 'calls': 'int32',\n",
    " 'minutes': 'float32',\n",
    " 'messages': 'int16',\n",
    " 'mb_used': 'float32',\n",
    " 'is_ultra': 'int8'}\n",
    "\n",
    "df = df.astype(df_type_dict)\n",
    "\n",
    "# убедимся что замена прошла так как задумано\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имена столбцов с \"фичами\" сохраним в списке x_col, столбец который мы будем предсказывать в списке y_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calls', 'minutes', 'messages', 'mb_used'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col = df.columns.drop('is_ultra')\n",
    "x_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные сначала на тестовую и полную тренировачную выбоки, а полную тренировачную выбоку разобъем на неоседственно трениовачную выбоку и валидационную выбоку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "df_train, df_valid = train_test_split(df_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Желательно было напечатать размеры полученных наборов. Иногда это помогает избежать ошибок.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем следующие модели классификации:\n",
    "* дерево решений\n",
    "* случайный лес\n",
    "* логистическая регрессия\n",
    "* CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений\n",
    "Для дерева решений будем менять глубину дерева и найдем такую глубину дерева которая дает наилучшее accuracy на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля првильных ответов на валидационной выбоке: 0.7860696517412935 для дерева глубиной 6\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_depth = 0\n",
    "best_tree_score = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model.fit(df_train[x_col], df_train[y_col].values.ravel())\n",
    "    score = accuracy_score(df_valid[y_col], model.predict(df_valid[x_col]))\n",
    "    if score > best_tree_score:\n",
    "        best_tree_model = model\n",
    "        best_tree_depth = depth\n",
    "        best_tree_score = score\n",
    "print('Доля првильных ответов на валидационной выбоке:', best_tree_score, 'для дерева глубиной', best_tree_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес\n",
    "Для случайного леса так же будем переберать глубину дерева и кроме того число деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633fdc4ac63644c395c9c73f926c2b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Доля првильных ответов на валидационной выбоке: 0.8109452736318408 для деревьев глубиной 7\n",
      "Число деревьев: 3\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_depth = 0\n",
    "best_forest_n_estimators = 0\n",
    "best_forest_score = 0\n",
    "for n_estimators in tqdm(range (1, 51)):\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth, random_state=42)\n",
    "        model.fit(df_train[x_col], df_train[y_col].values.ravel())\n",
    "        score = accuracy_score(df_valid[y_col], model.predict(df_valid[x_col]))\n",
    "        if score > best_forest_score:\n",
    "            best_forest_model = model\n",
    "            best_forest_depth = depth\n",
    "            best_forest_n_estimators = n_estimators\n",
    "            best_forest_score = score\n",
    "\n",
    "print('Доля првильных ответов на валидационной выбоке:', best_forest_score, 'для деревьев глубиной', best_forest_depth)\n",
    "print('Число деревьев:', best_forest_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "Для логистической регрессии параметры подберем ручным перебором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля првильных ответов на валидационной выбоке: 0.7545605306799337\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=42, solver='liblinear', penalty='l1', intercept_scaling=10)\n",
    "logistic_regression_model.fit(df_train[x_col], df_train[y_col].values.ravel())\n",
    "logistic_regression_score = accuracy_score(df_valid[y_col], logistic_regression_model.predict(df_valid[x_col]))\n",
    "\n",
    "print('Доля првильных ответов на валидационной выбоке:', logistic_regression_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Не имеет смысла печатать так много знаков после запятой, достаточно 2-3: \"0.XXX\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "CatBoost используем с параметрами в основном по умолчанию, ограничим лишь число итераций (200) и количетво выводимой информации (информация выводится каждые 50 итеаций)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.083029\n",
      "0:\tlearn: 0.6599045\ttest: 0.6590437\tbest: 0.6590437 (0)\ttotal: 51ms\tremaining: 50.9s\n",
      "50:\tlearn: 0.4075682\ttest: 0.4569395\tbest: 0.4563372 (46)\ttotal: 757ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.3599120\ttest: 0.4584878\tbest: 0.4549443 (59)\ttotal: 1.62s\tremaining: 14.4s\n",
      "150:\tlearn: 0.3128304\ttest: 0.4709159\tbest: 0.4549443 (59)\ttotal: 2.41s\tremaining: 13.5s\n",
      "200:\tlearn: 0.2735947\ttest: 0.4765392\tbest: 0.4549443 (59)\ttotal: 3.27s\tremaining: 13s\n",
      "250:\tlearn: 0.2422955\ttest: 0.4878269\tbest: 0.4549443 (59)\ttotal: 4.05s\tremaining: 12.1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.4549442983\n",
      "bestIteration = 59\n",
      "\n",
      "Shrink model to first 60 iterations.\n",
      "Доля првильных ответов на валидационной выбоке: 0.8009950248756219\n"
     ]
    }
   ],
   "source": [
    "cat_boost_model = CatBoostClassifier(verbose=50, early_stopping_rounds=200, random_state=42)\n",
    "cat_boost_model.fit(df_train[x_col], df_train[y_col].values.ravel(),\n",
    "                    eval_set=(df_valid[x_col], df_valid[y_col].values.ravel()))\n",
    "\n",
    "cat_boost_score = accuracy_score(df_valid[y_col], cat_boost_model.predict(df_valid[x_col]))\n",
    "\n",
    "print('Доля првильных ответов на валидационной выбоке:', cat_boost_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Подбор параметров реализован абсолютно верно!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговая модель\n",
    "Финальную модель построим комбинацией трех моделей: модели случайного леса, модели логистической регрессии и CatBoost. Решающее правило при этом определим следующим образом: если две или три модели советуют тариф \"Ультра\" (прогнозируют единицу), то пользователю предлагается тариф \"Ультра\" (итоговый прогноз единица), иначе \"Смарт\" (нуль). Введем функцию sum_score_calc которая оценивает accuracy по данному решающему правилу и оценим accuracy на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_score_calc(df):\n",
    "    predict_sum = (best_forest_model.predict(df[x_col]) + \n",
    "                   logistic_regression_model.predict(df[x_col]) +\n",
    "                   cat_boost_model.predict(df[x_col]))\n",
    "    score = accuracy_score(df[y_col], (predict_sum >= 2)*1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля првильных ответов на валидационной выбоке: 0.8126036484245439\n"
     ]
    }
   ],
   "source": [
    "print('Доля првильных ответов на валидационной выбоке:', sum_score_calc(df_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Интересная идея объеденить несколько моделей. Вот <a href=\"https://habr.com/ru/post/430280/\">статья</a> на эту тему.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно введение решающего правило дало небольшой прирост accuracy на валидационной выборке по сравнению с моделью случайного леса (81,26 % против 81,09 % у леса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля првильных ответов на тестовой выбоке: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "print('Доля првильных ответов на тестовой выбоке:', sum_score_calc(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке итоговая модель дает accuracy близкий к тому что было получено на валидации, что может говорить о стабильности работы алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Тестирование сделано корректно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки модели на адекватность, сравним accuracy итоговой модели на тестовых данных с accuracy модели которая всегда предсказывает тариф \"Смарт\" (нуль)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027363184079602"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[y_col], [0]*len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель которая всегда предсказывает тариф \"Смарт\" на тестовой выборке дает accuracy - 70,27%. Учитывая что итоговая модель на тестовой выборке дает accuracy - 81,7%, эту модель можно считать адекватной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Идея и реализация корректны. В будущем советую использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\"> DummyClassifier </a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. В работе была оценена возможность использования следующих алгоритмов:\n",
    "    * дерево решений\n",
    "    * случайный лес\n",
    "    * логистическая регрессия\n",
    "    * CatBoost\n",
    "    \n",
    "* Оптимизированы параметры алгоритмов\n",
    "* Предложено решающее правило по которому сформирована итоговая модель\n",
    "* Проведена оценка accuracy алгоритмов\n",
    "* Итоговая модель имеет accuracy на тестовой выборке 81,7 % и может быть использована для построения системы, способной на основе поведения клиентов предложить им новый тариф: «Смарт» или «Ультра».\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Радует, что ты не забыл про общий вывод.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
